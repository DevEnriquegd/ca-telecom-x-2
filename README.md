# ü§ñ Desaf√≠o: Predicci√≥n de Cancelaci√≥n (Churn) ‚Äî Telecom X (Machine Learning)

![Estado del Proyecto](https://img.shields.io/badge/Estado-Finalizado-success)
![Tecnolog√≠as](https://img.shields.io/badge/Tecnolog√≠as-Python%20%7C%20Scikit--Learn%20%7C%20XGBoost-orange)
![Modelo](https://img.shields.io/badge/Modelo-Random%20Forest%20--%20Champion-blue)

## üéØ 1. Objetivo del Proyecto
Tras el an√°lisis exploratorio de la Parte 1, Telecom X evoluciona hacia una estrategia predictiva. El objetivo es desarrollar un **pipeline de Machine Learning** robusto capaz de predecir el *churn* de clientes, permitiendo transitar de una cultura reactiva a una proactiva.

### Objetivos espec√≠ficos:
* **Tratamiento de Datos:** Pipeline de limpieza, codificaci√≥n y normalizaci√≥n.
* **Manejo de Desbalance:** Comparativa entre t√©cnicas de **Oversampling (SMOTE)** y **Undersampling**.
* **Modelado Avanzado:** Evaluaci√≥n de m√∫ltiples arquitecturas (KNN, Decision Tree, Random Forest, SVM y XGBoost).
* **Validaci√≥n Estad√≠stica:** Implementaci√≥n de **Stratified K-Fold Cross-Validation** para asegurar la estabilidad del modelo.

---

## üß† 2. Enfoque Metodol√≥gico
Se implement√≥ un pipeline estructurado bajo el criterio de **maximizaci√≥n del Recall**:

* **Preprocesamiento:** `OneHotEncoding` para variables categ√≥ricas y estandarizaci√≥n para modelos basados en distancia (KNN/SVM).
* **Estrategia de Balanceo:** Se determin√≥ que el **Undersampling** produce fronteras de decisi√≥n m√°s n√≠tidas y estables para este dataset en comparaci√≥n con SMOTE.
* **Validaci√≥n:** Uso de 5 pliegues (*folds*) para garantizar que las m√©tricas sean representativas de todo el dataset y no de una partici√≥n afortunada.

---

## üõ†Ô∏è 3. Tecnolog√≠as Utilizadas
| Librer√≠a | Prop√≥sito |
| :--- | :--- |
| **pandas / numpy** | Manipulaci√≥n y Feature Engineering. |
| **scikit-learn** | Pipeline de ML, m√©tricas y validaci√≥n cruzada. |
| **XGBoost** | Modelo de boosting de gradiente para comparaci√≥n de rendimiento. |
| **imblearn** | Balanceo de clases (SMOTE, Undersampling). |
| **pickle** | Serializaci√≥n del modelo "Champion". |

---

## üìä 4. Evaluaci√≥n de Modelos y Resultados Finales
Se prioriz√≥ el **Recall** (Sensibilidad) para minimizar los Falsos Negativos, dado que el costo de perder un cliente es superior al de una campa√±a de retenci√≥n.

### Comparativa de Validaci√≥n Cruzada (K-Folds)
| Modelo | Recall Promedio | Estabilidad (STD) | F1-Score |
| :--- | :---: | :---: | :---: |
| **Random Forest + Under** | **79.28%** | **¬±0.019** | **0.63** |
| SVM + Undersampling | 79.20% | ¬±0.007 | 0.62 |
| XGBoost + Undersampling | 75.61% | ¬±0.024 | 0.61 |
| KNN + SMOTE | 72.17% | ¬±0.026 | 0.55 |

**üèÜ Champion Model:** `Random Forest + Undersampling`.¬†
Este modelo logra capturar aproximadamente el **80% de las cancelaciones reales**, manteniendo un equilibrio √≥ptimo entre precisi√≥n y sensibilidad.

---

## üîé 5. Factores Clave de Cancelaci√≥n (Insights)
Basado en el atributo `feature_importances_` del modelo ganador:
1.  **Antig√ºedad (Tenure - 17.9%):** El mayor riesgo se concentra en los meses iniciales de contrato.
2.  **M√©tricas Financieras (Total/Monthly Charges - 27.3%):** Existe una alta sensibilidad al precio en los primeros ciclos de facturaci√≥n.
3.  **Tipo de Contrato (2 Year - 7.9%):** Los contratos a largo plazo reducen dr√°sticamente la probabilidad de fuga.
4.  **Servicios de Fibra √ìptica:** Identificado como un segmento con mayor tasa de deserci√≥n, sugiriendo revisi√≥n de calidad o precio.

---

## üöÄ 6. Recomendaciones Estrat√©gicas
* **Fidelizaci√≥n Temprana:** Implementar programas de acompa√±amiento (*onboarding*) en los primeros 6 meses.
* **Migraci√≥n de Pagos:** Fomentar el uso de pagos autom√°ticos para reducir la fricci√≥n del "punto de decisi√≥n" mensual asociado al *Electronic Check*.
* **Estrategia de Bundling:** Promover servicios de valor agregado (`Online Security`, `Tech Support`) para aumentar el costo de cambio percibido.

---

## ‚öôÔ∏è 7. Instalaci√≥n y Uso
1.  Instalar dependencias: `pip install -r requirements.txt`
2.  Ejecutar el notebook: `telecom_x_parte2.ipynb`
3.  Cargar el modelo exportado:
```python
import pickle
# El archivo exportado contiene un diccionario con el modelo y los nombres de las features
with open('champion.pkl', 'rb') as f:
    data = pickle.load(f)
    model = data['model']
```
