# ü§ñ Desaf√≠o: Predicci√≥n de Cancelaci√≥n (Churn) ‚Äî Telecom X (Machine Learning)

![Estado del Proyecto](https://img.shields.io/badge/Estado-Finalizado-success)
![Tecnolog√≠as](https://img.shields.io/badge/Tecnolog√≠as-Python%20%7C%20Scikit--Learn%20%7C%20XGBoost-orange)
![Modelo](https://img.shields.io/badge/Modelo-Random%20Forest%20--%20Champion-blue)

## üéØ 1. Objetivo del Proyecto
Tras el an√°lisis exploratorio de la Parte 1, Telecom X evoluciona hacia una estrategia predictiva. El objetivo es desarrollar un **pipeline de Machine Learning** robusto capaz de predecir el *churn* de clientes, permitiendo transitar de una cultura reactiva a una proactiva.

### Objetivos espec√≠ficos:
* **Tratamiento de Datos:** Pipeline de limpieza, codificaci√≥n y normalizaci√≥n.
* **Manejo de Desbalance:** Comparativa entre t√©cnicas de **Oversampling (SMOTE)** y **Undersampling**.
* **Modelado Avanzado:** Evaluaci√≥n de m√∫ltiples arquitecturas (KNN, Decision Tree, Random Forest, SVM y XGBoost).
* **Validaci√≥n Estad√≠stica:** Implementaci√≥n de **Stratified K-Fold Cross-Validation** para asegurar la estabilidad del modelo.

---

## üß† 2. Enfoque Metodol√≥gico
Se implement√≥ un pipeline estructurado bajo el criterio de **maximizaci√≥n del Recall**:

* **Preprocesamiento:** `OneHotEncoding` para variables categ√≥ricas y estandarizaci√≥n para modelos basados en distancia (KNN/SVM).
* **Estrategia de Balanceo:** Se determin√≥ que el **Undersampling** produce fronteras de decisi√≥n m√°s n√≠tidas y estables para este dataset en comparaci√≥n con SMOTE.
* **Validaci√≥n:** Uso de 5 pliegues (*folds*) para garantizar que las m√©tricas sean representativas de todo el dataset y no de una partici√≥n afortunada.

---

## üõ†Ô∏è 3. Tecnolog√≠as Utilizadas

| Categor√≠a | Herramientas / Librer√≠as | Prop√≥sito Espec√≠fico |
| :--- | :--- | :--- |
| **Lenguaje** | `Python 3.x` | Base del desarrollo del proyecto. |
| **An√°lisis de Datos** | `pandas`, `numpy` | Manipulaci√≥n de DataFrames y operaciones vectoriales. |
| **Visualizaci√≥n** | `matplotlib`, `seaborn` | Gr√°ficos estad√≠sticos y visualizaci√≥n de importancia de variables. |
| **Preprocesamiento** | `OneHotEncoder`, `ColumnTransformer` | Codificaci√≥n de variables categ√≥ricas y transformaci√≥n modular. |
| **Modelado (Core)** | `Scikit-learn`, `XGBoost`, `SVM` | Entrenamiento de modelos de clasificaci√≥n y ensambles. |
| **Pipeline y Flujo** | `sklearn.pipeline.Pipeline` | Automatizaci√≥n de la cadena de transformaci√≥n y predicci√≥n. |
| **Validaci√≥n Avanzada** | `StratifiedKFold`, `cross_val_score` | Validaci√≥n cruzada robusta para asegurar la estabilidad. |
| **Balanceo de Clases** | `SMOTE`, `RandomUnderSampler` | Mitigaci√≥n del sesgo de clases mediante sobre/submuestreo. |
| **Persistencia** | `pickle` | Exportaci√≥n y serializaci√≥n del modelo "Champion". |

---

## üìä 4. Evaluaci√≥n de Experimentos y Resultados

Para seleccionar la mejor estrategia, se realiz√≥ una comparativa inicial evaluando el rendimiento puntual de los modelos combinados con t√©cnicas de balanceo (SMOTE y Undersampling).

### A. Resultados de la Fase de Experimentaci√≥n (Hold-out)
En esta fase se midi√≥ el impacto directo del balanceo en la matriz de confusi√≥n y m√©tricas clave:

| Modelo + Estrategia | TP | TN | FN | FP | Recall | Precision | ROC-AUC |
| :--- | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
| **RandomForest + SMOTE** | 457 | 1098 | 104 | 454 | **81.46%** | 50.16% | 0.834 |
| **RandomForest + Under** | 454 | 1101 | 107 | 451 | **80.93%** | 50.17% | 0.836 |
| XGBoost + Under | 451 | 1105 | 110 | 447 | 80.39% | 50.22% | 0.831 |
| SVM + Under | 438 | 1116 | 123 | 436 | 78.07% | 50.11% | 0.819 |
| XGBoost + SMOTE | 437 | 1123 | 124 | 429 | 77.90% | 50.46% | 0.831 |
| SVM + SMOTE | 428 | 1126 | 133 | 426 | 76.29% | 50.12% | 0.822 |
| KNN + Under | 332 | 1259 | 229 | 293 | 59.18% | 53.12% | 0.783 |
| KNN + SMOTE | 142 | 1430 | 419 | 122 | 25.31% | 53.79% | 0.754 |


### B. Validaci√≥n Cruzada (La Prueba de Consistencia)
Debido a la cercan√≠a en los resultados entre SMOTE y Undersampling para Random Forest, se aplic√≥ **Stratified K-Fold** para determinar cu√°l t√©cnica era m√°s estable ante diferentes particiones de datos:

| Modelo (K-Folds) | Recall Promedio | Estabilidad (STD) | F1-Score | Estado |
| :--- | :--- | :--- | :--- | :--- |
| **Random Forest + Under** | **79.28%** | **¬±0.019** | **0.63** | **CHAMPION** |
| SVM + Under | 79.20% | ¬±0.007 | 0.62 | Finalista |
| KNN + SMOTE | 72.17% | ¬±0.026 | 0.55 | Descartado |

**An√°lisis de Selecci√≥n:** Aunque SMOTE alcanz√≥ un pico de Recall del 81.46% en la prueba inicial, el **Undersampling** demostr√≥ una mayor robustez y un mejor F1-Score general en la validaci√≥n cruzada, lo que lo convierte en la opci√≥n m√°s fiable para producci√≥n.

---

## üîé 5. Factores Clave de Cancelaci√≥n (Insights)
Basado en el atributo `feature_importances_` del modelo ganador:
1.  **Antig√ºedad (Tenure - 17.9%):** El mayor riesgo se concentra en los meses iniciales de contrato.
2.  **M√©tricas Financieras (Total/Monthly Charges - 27.3%):** Existe una alta sensibilidad al precio en los primeros ciclos de facturaci√≥n.
3.  **Tipo de Contrato (2 Year - 7.9%):** Los contratos a largo plazo reducen dr√°sticamente la probabilidad de fuga.
4.  **Servicios de Fibra √ìptica:** Identificado como un segmento con mayor tasa de deserci√≥n, sugiriendo revisi√≥n de calidad o precio.

---

## üöÄ 6. Recomendaciones Estrat√©gicas
* **Fidelizaci√≥n Temprana:** Implementar programas de acompa√±amiento (*onboarding*) en los primeros 6 meses.
* **Migraci√≥n de Pagos:** Fomentar el uso de pagos autom√°ticos para reducir la fricci√≥n del "punto de decisi√≥n" mensual asociado al *Electronic Check*.
* **Estrategia de Bundling:** Promover servicios de valor agregado (`Online Security`, `Tech Support`) para aumentar el costo de cambio percibido.

---

## ‚öôÔ∏è 7. Instalaci√≥n y Uso
1.  Instalar dependencias: `pip install -r requirements.txt`
2.  Ejecutar el notebook: `telecom_x_parte2.ipynb`
3.  Cargar el modelo exportado:

```python
import pickle

# Cargar el diccionario que contiene el modelo y metadatos
with open('champion.pkl', 'rb') as f:
    data = pickle.load(f)

# Acceder a los componentes
model = data['model']
features = data['features']
```

## ü§ù 8. Autor√≠a
Proyecto desarrollado por Enrique como Analista Junior de Machine Learning para el desaf√≠o Telecom X.
